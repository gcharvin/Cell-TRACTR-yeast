lr: 0.0002
lr_backbone_names: ['backbone.0']
lr_backbone: 0.00002
lr_linear_proj_names: ['reference_points', 'sampling_offsets']
lr_linear_proj_mult: 0.1
lr_track: 0.0001
object_detection_only: false
overwrite_lrs: false
overwrite_lr_scheduler: false
batch_size: 2
weight_decay: 0.0001
epochs: 50
lr_drop: 40
epoch_to_start_using_flexible_divisions: 5
use_prev_prev_frame: true
# gradient clipping max norm
clip_max_norm: 0.1
# Deformable DETR
deformable: true
with_box_refine: true
two_stage: true
# Model parameters
freeze_detr: false
load_mask_head_from_model: null
# Backbone
# Name of the convolutional backbone to use. ('resnet50', 'resnet101')
backbone: resnet50
# If true, we replace stride with dilation in the last convolutional block (DC5)
dilation: false
# Type of positional embedding to use on top of the image features. ('sine', 'learned')
position_embedding: sine
# Number of feature levels the encoder processes from the backbone
num_feature_levels: 3
# Transformer
# Number of encoding layers in the transformer
enc_layers: 6
# Number of decoding layers in the transformer
dec_layers: 6
# Intermediate size of the feedforward layers in the transformer blocks
dim_feedforward: 1024
# Size of the embeddings (dimension of the transformer)
hidden_dim: 288
# Dropout applied in the transformer
dropout: 0.1
# Number of attention heads inside the transformer's attentions
nheads: 8
# Number of object queries
num_queries: 30
pre_norm: false
dec_n_points: 4
enc_n_points: 4
# DAB-DETR - denoising parameters
use_dab: true
dn_track: true
dn_track_add_object_queries: true
dn_track_l1: 0.1
dn_track_l2: 0.05
dn_object: false
dn_label: 0.3
dn_object_l1: 0.2
dn_object_l2: 0.1
dn_enc: true
dn_enc_l1: 0.2
dn_enc_l2: 0.1
# Embeddings to differentiate object vs track queries
refine_track_queries: true
refine_object_queries: true
refine_div_track_queries: false
use_div_ref_pts: true
init_enc_queries_embeddings: false
init_boxes_from_masks: false
# Tracking
tracking: true
# In addition to detection also run tracking evaluation with default configuration from `cfgs/track.yaml`
tracking_eval: true
# Range of possible random previous frames
track_prev_prev_frame: True
track_backprop_prev_frame: False
# only for vanilla DETR
track_query_false_positive_eos_weight: true
track_attention: false
multi_frame_attention: true
multi_frame_encoding: true
multi_frame_attention_separate_encoder: true
merge_frame_features: true
overflow_boxes: true
# Segmentation
masks: true
mask_dim: 288
enc_masks: false
# Matcher
# Class coefficient in the matching cost
set_cost_class: 2.0
# L1 box coefficient in the matching cost
set_cost_bbox: 5.0
# giou box coefficient in the matching cost
set_cost_giou: 2.0
set_cost_mask: 5.0
set_cost_dice: 2.0
match_masks: false
num_points: 10000
# Loss
# Disables auxiliary decoding losses (loss at each layer)
aux_loss: true
return_intermediate_masks: false
group_object_coef: 1.0
dn_object_coef: 1.0
dn_track_coef: 1.0
mask_loss_coef: 20.0
mask_weight_cells_coef: 1.0 
mask_weight_target_cell_coef: 2.0
dice_loss_coef: 4.0
loss_coef: 1.0 # This is just a formality
cls_loss_coef: 1.0 
bbox_loss_coef: 5.0
giou_loss_coef: 2.0
div_loss_coef: 2.0 
track_div_loss_coef: 2.0
object_queies_loss_coef: 1.0
no_data_aug: false
# Relative classification weight of the no-object class
eos_coef: 0.1
focal_loss: true
focal_alpha: 0.25
focal_gamma: 2
# Dataset
dataset: moma
# Number of plots
num_plots: 10
# Miscellaneous
# path where to save, empty for no saving
output_dir: /projectnb/dunlop/ooconnor/object_detection/cell-trackformer/results
data_dir: /projectnb/dunlop/ooconnor/object_detection/data
# device to use for training / testing
device: cuda
seed: 42
# resume from checkpoint
resume: ''
resume_shift_neuron: False
# resume optimization from checkpoint
resume_optim: false
# resume Visdom visualization
resume_vis: false
start_epoch: 1
eval_only: false
eval_train: false
num_workers: 0
val_interval: 5
debug: false
# epoch interval for model saving. if 0 only save last and best models
save_model_interval: false
# distributed training parameters
# number of distributed processes
world_size: 1
# url used to set up distributed training
dist_url: env://
cls_threshold: 0.5
iou_threshold: 0.75
display_all: True
